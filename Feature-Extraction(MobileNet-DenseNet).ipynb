{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/DakshLadha/Alarm-Clock/blob/main/Feature-Extraction(MobileNet-DenseNet).ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TbFijP1rFCnj",
        "outputId": "c9306ca6-fc43-4e90-9fe9-f70945e12a9f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "YdPkeAL2aJx3"
      },
      "outputs": [],
      "source": [
        "from collections import Counter\n",
        "import cv2\n",
        "import time\n",
        "import glob\n",
        "import skimage\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import seaborn as sn\n",
        "from tqdm import tqdm\n",
        "from os import listdir\n",
        "import matplotlib.pyplot as plt\n",
        "from skimage.transform import resize\n",
        "from collections import Counter\n",
        "import warnings\n",
        "warnings.filterwarnings(\"ignore\")\n",
        "\n",
        "# !pip install FS\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "#from drive.MyDrive.FS.woa import jfs   # change this to switch algorithm\n",
        "\n",
        "sn.set()\n",
        "\n",
        "from sklearn.pipeline import make_pipeline\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.feature_selection import SelectFromModel\n",
        "from time import time\n",
        "\n",
        "from sklearn import metrics\n",
        "from sklearn.utils import shuffle\n",
        "from sklearn import metrics\n",
        "from sklearn.metrics import confusion_matrix, classification_report, accuracy_score,f1_score,recall_score,cohen_kappa_score,precision_score\n",
        "from sklearn.utils import compute_class_weight\n",
        "from sklearn.preprocessing import MinMaxScaler,LabelBinarizer, LabelEncoder\n",
        "from sklearn.neighbors import KNeighborsClassifier # KNeighborsClassifier\n",
        "from sklearn.svm import SVC # SVM\n",
        "from sklearn.ensemble import RandomForestClassifier # RandomForestClassifier\n",
        "from sklearn.ensemble import AdaBoostClassifier # AdaBoostClassifier\n",
        "from xgboost import XGBClassifier # XGBClassifier\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.decomposition import PCA\n",
        "\n",
        "import tensorflow\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "from tensorflow.keras.metrics import AUC\n",
        "from tensorflow.keras.preprocessing import image\n",
        "from tensorflow.keras.models import Model, Sequential\n",
        "from tensorflow.keras.applications.vgg16 import VGG16 # VGG16\n",
        "from tensorflow.keras.applications.vgg19 import VGG19 # VGG19\n",
        "from tensorflow.keras.applications.resnet50 import ResNet50 # ResNet50\n",
        "#from tensorflow.keras.applications.resnet9 import ResNet9 # ResNet50\n",
        "from tensorflow.keras.applications import ResNet101,InceptionResNetV2 # ResNet 101\n",
        "from tensorflow.keras.applications.xception import Xception # Xception\n",
        "from tensorflow.keras.applications.mobilenet import MobileNet # MobileNet\n",
        "from tensorflow.keras.applications.densenet import DenseNet169 # DenseNet169\n",
        "from tensorflow.keras.applications.densenet import DenseNet121 # DenseNet121\n",
        "from tensorflow.keras.applications.mobilenet_v2 import MobileNetV2 # MobileNetV2\n",
        "from tensorflow.keras.applications.inception_v3 import InceptionV3 # InceptionV3\n",
        "from tensorflow.keras.layers import Input, Dense, Dropout, BatchNormalization, Flatten, Activation, GlobalAveragePooling2D,Conv2D, MaxPooling2D\n",
        "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "Bu2JYHabaWre"
      },
      "outputs": [],
      "source": [
        "def loadImages(path, limit=100):\n",
        "    sample = []\n",
        "    count = 0\n",
        "\n",
        "    for filename in glob.glob(path):\n",
        "        if limit is not None and count >= limit:\n",
        "            break\n",
        "\n",
        "        img = cv2.imread(filename)\n",
        "        img = skimage.transform.resize(img, (224, 224, 3))\n",
        "        IMG = np.array(img)\n",
        "        sample.append(IMG)\n",
        "\n",
        "        count += 1\n",
        "\n",
        "    return sample"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "bRWkrFHQaeM6"
      },
      "outputs": [],
      "source": [
        "train_path1 = '/content/drive/MyDrive/Peach___Bacterial_spot/*.JPG'\n",
        "train_path2 = '/content/drive/MyDrive/Peach___healthy/*.JPG'\n",
        "train_path3 = '/content/drive/MyDrive/Strawberry___Leaf_scorch/*.JPG'\n",
        "train_path4 = '/content/drive/MyDrive/Strawberry___healthy/*.JPG'\n",
        "#train_path5 = 'drive/My Drive/train/tlb/*.JPG'\n",
        "#train_path6 = 'drive/My Drive/train/tlm/*.JPG'\n",
        "#train_path7 = 'drive/My Drive/train/ttylcv/*.JPG'\n",
        "#train_path8 = 'drive/My Drive/train/tts/*.JPG'\n",
        "#train_path9 = 'drive/My Drive/train/ttmv/*.JPG'\n",
        "#train_path10 = 'drive/My Drive/train/tslf/*.JPG'\n",
        "\n",
        "\n",
        "train_1 = loadImages(train_path1)\n",
        "train_2 = loadImages(train_path2)\n",
        "train_3 = loadImages(train_path3)\n",
        "train_4 = loadImages(train_path4)\n",
        "#train_5 = loadImages(train_path5)\n",
        "#train_6 = loadImages(train_path6)\n",
        "#train_7 = loadImages(train_path7)\n",
        "#train_8 = loadImages(train_path8)\n",
        "#train_9 = loadImages(train_path9)\n",
        "#train_10 = loadImages(train_path10)\n",
        "\n",
        "#%% CREATION OF DATASETS"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xO8EAWWKNQfh",
        "outputId": "a788b658-e1b0-4ac6-8f04-2371675f3ab5"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Entire data size: (400, 2)\n"
          ]
        }
      ],
      "source": [
        "df_train_1 = pd.DataFrame({'image':train_1, 'label': '1'})\n",
        "df_train_2 = pd.DataFrame({'image':train_2, 'label': '2'})\n",
        "df_train_3 = pd.DataFrame({'image':train_3, 'label': '3'})\n",
        "df_train_4 = pd.DataFrame({'image':train_4, 'label': '4'})\n",
        "#df_train_5 = pd.DataFrame({'image':train_5, 'label': '5'})\n",
        "#df_train_6 = pd.DataFrame({'image':train_6, 'label': '6'})\n",
        "#df_train_7 = pd.DataFrame({'image':train_7, 'label': '7'})\n",
        "#df_train_8 = pd.DataFrame({'image':train_8, 'label': '8'})\n",
        "#df_train_9 = pd.DataFrame({'image':train_9, 'label': '9'})\n",
        "#df_train_10 = pd.DataFrame({'image':train_10, 'label': '10'})\n",
        "\n",
        "final_data = [df_train_1,df_train_2, df_train_3, df_train_4]\n",
        "final_data = pd.concat(final_data)\n",
        "\n",
        "print(\"Entire data size:\",final_data.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6LR6Uw30IJD5",
        "outputId": "be39e273-dac1-4b6c-dbe2-4b59e561bf18"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Labels Count: Counter({'1': 100, '2': 100, '3': 100, '4': 100})\n",
            "400\n",
            "280\n"
          ]
        }
      ],
      "source": [
        "#%% TRAIN LABEL SEPARATION\n",
        "\n",
        "train_data = final_data['image']\n",
        "labels = final_data['label']\n",
        "\n",
        "print(\"Labels Count:\",Counter(np.array(labels)))\n",
        "\n",
        "onehot = LabelEncoder()\n",
        "labels = onehot.fit_transform(labels)\n",
        "print(labels.size)\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(train_data, labels,\n",
        "                                                  test_size = 0.3,\n",
        "                                                  stratify = labels,\n",
        "                                                  )\n",
        "\n",
        "X_train = np.array(X_train)\n",
        "X_test = np.array(X_test)\n",
        "\n",
        "print(y_train.size)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "P8fFaC0bGLtP",
        "outputId": "cf719838-9303-4e92-db1f-59e7d812e772"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(400,)\n",
            "[0 1 2 3]\n"
          ]
        }
      ],
      "source": [
        "print(train_data.shape)\n",
        "print(np.unique(y_train))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2sBEdOGmN2cL",
        "outputId": "60207b27-f27b-46a4-b6a2-d5d97acae297"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(280, 224, 224, 3)\n",
            "(120, 224, 224, 3)\n"
          ]
        }
      ],
      "source": [
        "x_train = np.empty((len(X_train),X_train[0].shape[0],X_train[0].shape[1],X_train[0].shape[2]))\n",
        "for i,x in enumerate(X_train):\n",
        "    x_train[i]=X_train[i]\n",
        "print(x_train.shape)\n",
        "x_test= np.empty((len(X_test),X_test[0].shape[0],X_test[0].shape[1],X_test[0].shape[2]))\n",
        "for i,x in enumerate(X_test):\n",
        "    x_test[i]=X_test[i]\n",
        "print(x_test.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6GRoAx1cpGui",
        "outputId": "f5a10db1-55ff-4572-ddae-06a5b61585fe"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/mobilenet_v2/mobilenet_v2_weights_tf_dim_ordering_tf_kernels_1.0_224_no_top.h5\n",
            "\u001b[1m9406464/9406464\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 0us/step\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 1s/step\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 2s/step\n",
            "[[0.        2.8985481 0.        ... 0.        0.        0.       ]\n",
            " [0.        0.        0.        ... 0.        0.        0.       ]\n",
            " [0.        0.        0.        ... 0.        0.        0.       ]\n",
            " ...\n",
            " [0.        3.0746684 0.        ... 0.        0.        0.       ]\n",
            " [0.        0.        0.        ... 0.        0.        0.       ]\n",
            " [0.        5.129878  0.        ... 0.        0.        0.       ]]\n",
            "[[0.         0.         0.         ... 0.         0.         0.        ]\n",
            " [0.         3.1745105  0.         ... 0.         0.         0.        ]\n",
            " [0.         0.98361254 0.         ... 0.         0.         0.        ]\n",
            " ...\n",
            " [0.         0.61998844 0.         ... 0.         0.         0.        ]\n",
            " [0.         0.         0.         ... 0.         0.         0.04434633]\n",
            " [0.         0.90555525 0.         ... 0.         0.         0.        ]]\n"
          ]
        }
      ],
      "source": [
        "base_model = MobileNetV2(include_top=False, weights='imagenet', input_shape=(224,224,3))\n",
        "x = base_model.output\n",
        "x =  Dropout(0.5)(x)\n",
        "x = Flatten()(x)\n",
        "\n",
        "model_feat = Model(inputs=base_model.input,outputs=x)\n",
        "\n",
        "mobile_train_features = model_feat.predict(x_train)\n",
        "mobile_test_features=model_feat.predict(x_test)\n",
        "print(mobile_train_features)\n",
        "print(mobile_test_features)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lOwukHyNVcp4",
        "outputId": "ee1d9bac-93af-4a46-8a39-da26cef9fab3"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/densenet/densenet121_weights_tf_dim_ordering_tf_kernels_notop.h5\n",
            "\u001b[1m29084464/29084464\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 0us/step\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m64s\u001b[0m 7s/step\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 6s/step\n",
            "[[0.0000000e+00 4.4753030e-04 0.0000000e+00 ... 6.5886045e-01\n",
            "  0.0000000e+00 2.8094332e+00]\n",
            " [5.2728155e-04 1.0579238e-03 0.0000000e+00 ... 3.1045461e+00\n",
            "  8.7979108e-02 0.0000000e+00]\n",
            " [0.0000000e+00 0.0000000e+00 7.1028774e-03 ... 0.0000000e+00\n",
            "  0.0000000e+00 1.0765806e-01]\n",
            " ...\n",
            " [0.0000000e+00 0.0000000e+00 0.0000000e+00 ... 2.6031337e+00\n",
            "  7.4842721e-02 0.0000000e+00]\n",
            " [0.0000000e+00 0.0000000e+00 4.9169175e-05 ... 1.9374096e+00\n",
            "  0.0000000e+00 0.0000000e+00]\n",
            " [0.0000000e+00 4.2393757e-04 0.0000000e+00 ... 2.9219704e+00\n",
            "  0.0000000e+00 0.0000000e+00]]\n",
            "[[0.0000000e+00 0.0000000e+00 1.7534562e-03 ... 2.4203317e+00\n",
            "  0.0000000e+00 0.0000000e+00]\n",
            " [0.0000000e+00 0.0000000e+00 1.6948424e-03 ... 8.4434261e+00\n",
            "  0.0000000e+00 5.2924490e-01]\n",
            " [1.2036539e-03 2.2797046e-02 0.0000000e+00 ... 2.3833659e+00\n",
            "  7.2246641e-02 1.8010060e+00]\n",
            " ...\n",
            " [0.0000000e+00 0.0000000e+00 4.3366929e-03 ... 1.9362767e+00\n",
            "  0.0000000e+00 0.0000000e+00]\n",
            " [0.0000000e+00 7.9728309e-03 0.0000000e+00 ... 6.8220288e-01\n",
            "  0.0000000e+00 4.3029970e-01]\n",
            " [0.0000000e+00 4.8249760e-03 0.0000000e+00 ... 2.7533765e+00\n",
            "  0.0000000e+00 1.0058045e+00]]\n"
          ]
        }
      ],
      "source": [
        "base_model = DenseNet121(include_top=False, weights='imagenet', input_shape=(224,224,3))\n",
        "y = base_model.output\n",
        "y =  Dropout(0.5)(y)\n",
        "y = Flatten()(y)\n",
        "\n",
        "model_feat = Model(inputs=base_model.input,outputs=y)\n",
        "\n",
        "dense_train_features = model_feat.predict(x_train)\n",
        "dense_test_features=model_feat.predict(x_test)\n",
        "print(dense_train_features)\n",
        "print(dense_test_features)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "csv_mobile = pd.DataFrame(mobile_train_features)\n",
        "csv_densenet = pd.DataFrame(dense_train_features)\n",
        "print(np.unique(y_train))\n",
        "csv_label = pd.DataFrame(y_train)\n",
        "final_csv = [csv_mobile,csv_densenet,csv_label]\n",
        "#final_csv = pd.concat(final_csv,axis=1)\n",
        "#final_csv.to_csv('train_features_2.csv')\n",
        "new = pd.concat(final_csv, axis=1, join='inner')\n",
        "new.to_csv('train_features_2.csv')\n",
        "!cp train_features_2.csv \"drive/My Drive/\""
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_OB1DRgDF95q",
        "outputId": "441306d8-a3a5-448b-d936-23ee0b1cfc8b"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[0 1 2 3]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "cYxr8lu45_je"
      },
      "outputs": [],
      "source": [
        "train_features = np.append(mobile_train_features,dense_train_features,axis=1)\n",
        "test_features = np.append(mobile_test_features,dense_test_features,axis=1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "Lvv5S-N5eNMO",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1a70ce06-2009-49f9-9293-25848ac203f8"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "length X_train: 224\n",
            "length y_train: 224\n",
            "length X_val: 56\n",
            "length y_val: 56\n",
            "length X_test: 120\n",
            "length y_test: 120\n"
          ]
        }
      ],
      "source": [
        "x_train_acc, x_val_acc, y_train_acc, y_val_acc = train_test_split(train_features,y_train,\n",
        "                                                  test_size = 0.2,\n",
        "                                                  stratify = y_train,\n",
        "                                                  shuffle = True,\n",
        "                                                  random_state = 42)\n",
        "X_test,y_test=test_features,y_test\n",
        "\n",
        "print('length X_train:', len(x_train_acc))\n",
        "print('length y_train:', len(y_train_acc))\n",
        "\n",
        "print('length X_val:',  len(x_val_acc))\n",
        "print('length y_val:', len(y_val_acc))\n",
        "\n",
        "print('length X_test:',  len(X_test))\n",
        "print('length y_test:', len(y_test))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "iEWVUUS_eRml"
      },
      "outputs": [],
      "source": [
        "def classifier_summary(pipeline, X_train, y_train, X_val, y_val,X_test,y_test):\n",
        "\n",
        "    start = time()\n",
        "    sentiment_fit = pipeline.fit(X_train, y_train)\n",
        "    end = time()\n",
        "\n",
        "    y_pred_train= sentiment_fit.predict(X_train)\n",
        "    y_pred_val = sentiment_fit.predict(X_val)\n",
        "    y_pred_test = sentiment_fit.predict(X_test)\n",
        "\n",
        "    train_accuracy = np.round(accuracy_score(y_train, y_pred_train),4)*100\n",
        "    train_precision = np.round(precision_score(y_train, y_pred_train, average='weighted'),4)\n",
        "    train_recall = np.round(recall_score(y_train, y_pred_train, average='weighted'),4)\n",
        "    train_F1 = np.round(f1_score(y_train, y_pred_train, average='weighted'),4)\n",
        "    train_kappa =  np.round(cohen_kappa_score(y_train, y_pred_train),4)\n",
        "    train_confusion_matrix = confusion_matrix(y_train,y_pred_train)\n",
        "\n",
        "    val_accuracy = np.round(accuracy_score(y_val, y_pred_val),4)*100\n",
        "    val_precision = np.round(precision_score(y_val, y_pred_val, average='weighted'),4)\n",
        "    val_recall = np.round(recall_score(y_val, y_pred_val, average='weighted'),4)\n",
        "    val_F1 = np.round(f1_score(y_val, y_pred_val, average='weighted'),4)\n",
        "    val_kappa =  np.round(cohen_kappa_score(y_val, y_pred_val),4)\n",
        "    val_confusion_matrix = confusion_matrix(y_val,y_pred_val)\n",
        "\n",
        "    test_accuracy = np.round(accuracy_score(y_test, y_pred_test),4)*100\n",
        "    test_precision = np.round(precision_score(y_test, y_pred_test, average='weighted'),4)\n",
        "    test_recall = np.round(recall_score(y_test, y_pred_test, average='weighted'),4)\n",
        "    test_F1 = np.round(f1_score(y_test, y_pred_test, average='weighted'),4)\n",
        "    test_kappa =  np.round(cohen_kappa_score(y_test, y_pred_test),4)\n",
        "    test_confusion_matrix = confusion_matrix(y_test,y_pred_test)\n",
        "\n",
        "\n",
        "    print()\n",
        "    print(\"Time taken : {}\".format(end-start))\n",
        "    print('------------------------ Train Set Metrics------------------------')\n",
        "    print()\n",
        "    print(\"accuracy : {}%\".format(train_accuracy))\n",
        "    print(\"F1_score : {}\".format(train_F1))\n",
        "    print(\"Cohen Kappa Score : {} \".format(train_kappa))\n",
        "    print(\"Recall : {}\".format(train_recall))\n",
        "    print(\"Precision : {}\".format(train_precision))\n",
        "    print(\"Confusion Matrix :\\n {}\".format(train_confusion_matrix))\n",
        "\n",
        "    print()\n",
        "    print('------------------------ Validation Set Metrics------------------------')\n",
        "    print()\n",
        "    print(\"accuracy : {}%\".format(val_accuracy))\n",
        "    print(\"F1_score : {}\".format(val_F1))\n",
        "    print(\"Cohen Kappa Score : {} \".format(val_kappa))\n",
        "    print(\"Recall : {}\".format(val_recall))\n",
        "    print(\"Precision : {}\".format(val_precision))\n",
        "    print(\"Confusion Matrix :\\n {}\".format(val_confusion_matrix))\n",
        "\n",
        "    print()\n",
        "    print('------------------------ Test Set Metrics------------------------')\n",
        "    print()\n",
        "    print(\"accuracy : {}%\".format(test_accuracy))\n",
        "    print(\"F1_score : {}\".format(test_F1))\n",
        "    print(\"Cohen Kappa Score : {} \".format(test_kappa))\n",
        "    print(\"Recall : {}\".format(test_recall))\n",
        "    print(\"Precision : {}\".format(test_precision))\n",
        "    print(\"Confusion Matrix : {}\".format(test_confusion_matrix))\n",
        "\n",
        "    print(\"-\"*80)\n",
        "    print()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "2ZZ4I-DueVRo"
      },
      "outputs": [],
      "source": [
        "names = [\n",
        "        'SVM',\n",
        "        \"Random Forest Classifier\",\n",
        "        \"AdaBoost Classifier\",\n",
        "        \"XGB Classifier\",\n",
        "         ]\n",
        "classifiers = [\n",
        "    SVC(),\n",
        "    RandomForestClassifier(),\n",
        "    AdaBoostClassifier(),\n",
        "        ]\n",
        "\n",
        "zipped_clf = zip(names,classifiers)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "GUlrJPkteZH9",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4e59a71f-4b5c-4ae8-ed90-e0cc81aa30da"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fitting SVM on features \n",
            "\n",
            "Time taken : 14.411726474761963\n",
            "------------------------ Train Set Metrics------------------------\n",
            "\n",
            "accuracy : 100.0%\n",
            "F1_score : 1.0\n",
            "Cohen Kappa Score : 1.0 \n",
            "Recall : 1.0\n",
            "Precision : 1.0\n",
            "Confusion Matrix :\n",
            " [[56  0  0  0]\n",
            " [ 0 56  0  0]\n",
            " [ 0  0 56  0]\n",
            " [ 0  0  0 56]]\n",
            "\n",
            "------------------------ Validation Set Metrics------------------------\n",
            "\n",
            "accuracy : 98.21%\n",
            "F1_score : 0.9821\n",
            "Cohen Kappa Score : 0.9762 \n",
            "Recall : 0.9821\n",
            "Precision : 0.9833\n",
            "Confusion Matrix :\n",
            " [[13  1  0  0]\n",
            " [ 0 14  0  0]\n",
            " [ 0  0 14  0]\n",
            " [ 0  0  0 14]]\n",
            "\n",
            "------------------------ Test Set Metrics------------------------\n",
            "\n",
            "accuracy : 96.67%\n",
            "F1_score : 0.9665\n",
            "Cohen Kappa Score : 0.9556 \n",
            "Recall : 0.9667\n",
            "Precision : 0.9706\n",
            "Confusion Matrix : [[26  4  0  0]\n",
            " [ 0 30  0  0]\n",
            " [ 0  0 30  0]\n",
            " [ 0  0  0 30]]\n",
            "--------------------------------------------------------------------------------\n",
            "\n",
            "Fitting Random Forest Classifier on features \n",
            "\n",
            "Time taken : 2.3463995456695557\n",
            "------------------------ Train Set Metrics------------------------\n",
            "\n",
            "accuracy : 100.0%\n",
            "F1_score : 1.0\n",
            "Cohen Kappa Score : 1.0 \n",
            "Recall : 1.0\n",
            "Precision : 1.0\n",
            "Confusion Matrix :\n",
            " [[56  0  0  0]\n",
            " [ 0 56  0  0]\n",
            " [ 0  0 56  0]\n",
            " [ 0  0  0 56]]\n",
            "\n",
            "------------------------ Validation Set Metrics------------------------\n",
            "\n",
            "accuracy : 96.43%\n",
            "F1_score : 0.9642\n",
            "Cohen Kappa Score : 0.9524 \n",
            "Recall : 0.9643\n",
            "Precision : 0.9667\n",
            "Confusion Matrix :\n",
            " [[13  1  0  0]\n",
            " [ 0 14  0  0]\n",
            " [ 0  0 13  1]\n",
            " [ 0  0  0 14]]\n",
            "\n",
            "------------------------ Test Set Metrics------------------------\n",
            "\n",
            "accuracy : 96.67%\n",
            "F1_score : 0.9665\n",
            "Cohen Kappa Score : 0.9556 \n",
            "Recall : 0.9667\n",
            "Precision : 0.9706\n",
            "Confusion Matrix : [[26  4  0  0]\n",
            " [ 0 30  0  0]\n",
            " [ 0  0 30  0]\n",
            " [ 0  0  0 30]]\n",
            "--------------------------------------------------------------------------------\n",
            "\n",
            "Fitting AdaBoost Classifier on features \n",
            "\n",
            "Time taken : 93.86831498146057\n",
            "------------------------ Train Set Metrics------------------------\n",
            "\n",
            "accuracy : 87.94999999999999%\n",
            "F1_score : 0.8736\n",
            "Cohen Kappa Score : 0.8393 \n",
            "Recall : 0.8795\n",
            "Precision : 0.9139\n",
            "Confusion Matrix :\n",
            " [[56  0  0  0]\n",
            " [25 31  0  0]\n",
            " [ 0  0 55  1]\n",
            " [ 0  0  1 55]]\n",
            "\n",
            "------------------------ Validation Set Metrics------------------------\n",
            "\n",
            "accuracy : 71.43%\n",
            "F1_score : 0.6844\n",
            "Cohen Kappa Score : 0.619 \n",
            "Recall : 0.7143\n",
            "Precision : 0.7308\n",
            "Confusion Matrix :\n",
            " [[12  2  0  0]\n",
            " [10  3  1  0]\n",
            " [ 0  0 14  0]\n",
            " [ 0  0  3 11]]\n",
            "\n",
            "------------------------ Test Set Metrics------------------------\n",
            "\n",
            "accuracy : 75.0%\n",
            "F1_score : 0.7433\n",
            "Cohen Kappa Score : 0.6667 \n",
            "Recall : 0.75\n",
            "Precision : 0.7684\n",
            "Confusion Matrix : [[26  3  1  0]\n",
            " [16 14  0  0]\n",
            " [ 0  1 26  3]\n",
            " [ 0  0  6 24]]\n",
            "--------------------------------------------------------------------------------\n",
            "\n"
          ]
        }
      ],
      "source": [
        "def classifier_comparator(X_train,y_train,X_val,y_val,X_test,y_test,classifier=zipped_clf):\n",
        "    result = []\n",
        "    for n,c in classifier:\n",
        "        checker_pipeline = Pipeline([\n",
        "            ('classifier', c)\n",
        "        ])\n",
        "        print(\"Fitting {} on features \".format(n))\n",
        "        #print(c)\n",
        "        classifier_summary(checker_pipeline,X_train, y_train, X_val, y_val,X_test,y_test)\n",
        "\n",
        "classifier_comparator(x_train_acc,y_train_acc,x_val_acc,y_val_acc,X_test,y_test,classifier=zipped_clf)"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}